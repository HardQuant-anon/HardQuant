[2026-01-13 16:08:05 root] (main.py 382): INFO === SWEEP RUN: letlr_1e-04_lwclr_1e-04 ===
[2026-01-13 16:08:05 root] (main.py 383): INFO Namespace(model='meta-llama/Meta-Llama-3-8B', cache_dir='./cache', output_dir='./log/llama-8b-w4a4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext103', nsamples=128, batch_size=1, seed=2, tasks='', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.0001, lwc_lr=0.0001, wd=0, epochs=20, let=True, lwc=True, aug_loss=False, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=False, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, eval_quant_before_ft=False, let_lr_grid='1e-4,1e-3,1e-2', lwc_lr_grid='1e-4,1e-3,1e-2')
[2026-01-13 16:08:26 root] (main.py 461): INFO load calibration from ./cache/dataloader_Meta_wikitext103_train_seqlen2048_ns128_seed2_meta-llama_Meta-Llama-3-8B.pt
[2026-01-13 16:08:26 root] (main.py 488): INFO === start quantization ===
[2026-01-13 16:08:26 root] (omniquant.py 50): INFO Starting ...
[2026-01-13 16:08:30 root] (omniquant.py 193): INFO === Start quantize layer 0 ===
[2026-01-13 16:08:36 root] (omniquant.py 274): INFO layer 0 iter 0 loss:7.050805288599804e-05 norm:8.862602953740861e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:08:40 root] (omniquant.py 274): INFO layer 0 iter 1 loss:7.279068086063489e-05 norm:1.0836356523213908e-05 max memory_allocated 9911.2626953125 
[2026-01-13 16:08:45 root] (omniquant.py 274): INFO layer 0 iter 2 loss:7.249740883708e-05 norm:1.0251837920804974e-05 max memory_allocated 9911.2626953125 
[2026-01-13 16:08:49 root] (omniquant.py 274): INFO layer 0 iter 3 loss:7.101763185346499e-05 norm:9.355885595141444e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:08:53 root] (omniquant.py 274): INFO layer 0 iter 4 loss:7.055734022287652e-05 norm:9.156248779618181e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:08:58 root] (omniquant.py 274): INFO layer 0 iter 5 loss:6.966698856558651e-05 norm:8.513166903867386e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:02 root] (omniquant.py 274): INFO layer 0 iter 6 loss:6.865592149551958e-05 norm:7.359276878560195e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:06 root] (omniquant.py 274): INFO layer 0 iter 7 loss:6.844189920229837e-05 norm:7.347295195359038e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:11 root] (omniquant.py 274): INFO layer 0 iter 8 loss:6.841649883426726e-05 norm:7.465651833626907e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:15 root] (omniquant.py 274): INFO layer 0 iter 9 loss:6.854115054011345e-05 norm:7.45838406146504e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:20 root] (omniquant.py 274): INFO layer 0 iter 10 loss:6.83140242472291e-05 norm:6.977113571338123e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:24 root] (omniquant.py 274): INFO layer 0 iter 11 loss:6.832573853898793e-05 norm:6.639890216320055e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:29 root] (omniquant.py 274): INFO layer 0 iter 12 loss:6.821058923378587e-05 norm:6.823272542533232e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:33 root] (omniquant.py 274): INFO layer 0 iter 13 loss:6.799918628530577e-05 norm:6.804234999435721e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:38 root] (omniquant.py 274): INFO layer 0 iter 14 loss:6.956285506021231e-05 norm:7.428925528074615e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:42 root] (omniquant.py 274): INFO layer 0 iter 15 loss:7.105473196133971e-05 norm:7.723383532720618e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:47 root] (omniquant.py 274): INFO layer 0 iter 16 loss:6.828697223681957e-05 norm:6.4250853029079735e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:51 root] (omniquant.py 274): INFO layer 0 iter 17 loss:6.746582948835567e-05 norm:6.288581516855629e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:09:55 root] (omniquant.py 274): INFO layer 0 iter 18 loss:6.916930578881875e-05 norm:7.039616775728064e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:10:00 root] (omniquant.py 274): INFO layer 0 iter 19 loss:6.880381988594308e-05 norm:6.718209988321178e-06 max memory_allocated 9911.2626953125 
[2026-01-13 16:10:01 root] (omniquant.py 193): INFO === Start quantize layer 1 ===
[2026-01-13 16:10:07 root] (omniquant.py 274): INFO layer 1 iter 0 loss:0.0072028422728180885 norm:nan max memory_allocated 9911.8955078125 
[2026-01-13 16:10:11 root] (omniquant.py 274): INFO layer 1 iter 1 loss:0.0071310196071863174 norm:0.0016630905447527766 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:16 root] (omniquant.py 274): INFO layer 1 iter 2 loss:0.007145389914512634 norm:0.001657396787777543 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:20 root] (omniquant.py 274): INFO layer 1 iter 3 loss:0.007144546136260033 norm:0.0016666847513988614 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:25 root] (omniquant.py 274): INFO layer 1 iter 4 loss:0.00697717210277915 norm:0.0016451525734737515 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:29 root] (omniquant.py 274): INFO layer 1 iter 5 loss:0.006926252041012049 norm:0.0016652873018756509 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:33 root] (omniquant.py 274): INFO layer 1 iter 6 loss:0.006913281511515379 norm:0.001659896457567811 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:38 root] (omniquant.py 274): INFO layer 1 iter 7 loss:0.006951136980205774 norm:0.0016624046256765723 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:42 root] (omniquant.py 274): INFO layer 1 iter 8 loss:0.006847533397376537 norm:0.0016366401687264442 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:47 root] (omniquant.py 274): INFO layer 1 iter 9 loss:0.006987036671489477 norm:0.0016325716860592365 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:51 root] (omniquant.py 274): INFO layer 1 iter 10 loss:0.0068886843509972095 norm:0.0016268027247861028 max memory_allocated 9911.8955078125 
[2026-01-13 16:10:56 root] (omniquant.py 274): INFO layer 1 iter 11 loss:0.006827992852777243 norm:0.0016218210803344846 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:00 root] (omniquant.py 274): INFO layer 1 iter 12 loss:0.006770516280084848 norm:0.0016441741026937962 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:05 root] (omniquant.py 274): INFO layer 1 iter 13 loss:0.006712515838444233 norm:0.001643069088459015 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:09 root] (omniquant.py 274): INFO layer 1 iter 14 loss:0.00668210256844759 norm:0.0016524032689630985 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:14 root] (omniquant.py 274): INFO layer 1 iter 15 loss:0.006604210939258337 norm:nan max memory_allocated 9911.8955078125 
[2026-01-13 16:11:18 root] (omniquant.py 274): INFO layer 1 iter 16 loss:0.0066536408849060535 norm:0.0016436276491731405 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:23 root] (omniquant.py 274): INFO layer 1 iter 17 loss:0.006677005439996719 norm:0.0016309423372149467 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:27 root] (omniquant.py 274): INFO layer 1 iter 18 loss:0.006770917680114508 norm:0.00164440693333745 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:32 root] (omniquant.py 274): INFO layer 1 iter 19 loss:0.006861095316708088 norm:0.0016693887300789356 max memory_allocated 9911.8955078125 
[2026-01-13 16:11:33 root] (omniquant.py 193): INFO === Start quantize layer 2 ===
[2026-01-13 16:11:39 root] (omniquant.py 274): INFO layer 2 iter 0 loss:0.007621230091899633 norm:9.115934517467394e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:11:44 root] (omniquant.py 274): INFO layer 2 iter 1 loss:0.007622869685292244 norm:9.104188939090818e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:11:49 root] (omniquant.py 274): INFO layer 2 iter 2 loss:0.007623882032930851 norm:9.046281047631055e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:11:53 root] (omniquant.py 274): INFO layer 2 iter 3 loss:0.007625705562531948 norm:8.984794112620875e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:11:58 root] (omniquant.py 274): INFO layer 2 iter 4 loss:0.007626032922416925 norm:8.948425966082141e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:02 root] (omniquant.py 274): INFO layer 2 iter 5 loss:0.007624943740665913 norm:8.900475950213149e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:07 root] (omniquant.py 274): INFO layer 2 iter 6 loss:0.007624594494700432 norm:8.758492913329974e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:11 root] (omniquant.py 274): INFO layer 2 iter 7 loss:0.007625097408890724 norm:8.640743908472359e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:16 root] (omniquant.py 274): INFO layer 2 iter 8 loss:0.007622948847711086 norm:8.447173604508862e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:20 root] (omniquant.py 274): INFO layer 2 iter 9 loss:0.007623618468642235 norm:8.387592242797837e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:25 root] (omniquant.py 274): INFO layer 2 iter 10 loss:0.007624161895364523 norm:8.370458817807958e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:29 root] (omniquant.py 274): INFO layer 2 iter 11 loss:0.007622097618877888 norm:8.279179019154981e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:34 root] (omniquant.py 274): INFO layer 2 iter 12 loss:0.007619758602231741 norm:8.202077879104763e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:38 root] (omniquant.py 274): INFO layer 2 iter 13 loss:0.007619879674166441 norm:8.152562804752961e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:43 root] (omniquant.py 274): INFO layer 2 iter 14 loss:0.00761857395991683 norm:8.013709884835407e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:47 root] (omniquant.py 274): INFO layer 2 iter 15 loss:0.007617831230163574 norm:7.995557098183781e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:52 root] (omniquant.py 274): INFO layer 2 iter 16 loss:0.007615929469466209 norm:7.973815081641078e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:12:56 root] (omniquant.py 274): INFO layer 2 iter 17 loss:0.007616597227752209 norm:7.932057633297518e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:13:01 root] (omniquant.py 274): INFO layer 2 iter 18 loss:0.0076166195794939995 norm:7.878575706854463e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:13:05 root] (omniquant.py 274): INFO layer 2 iter 19 loss:0.007616107817739248 norm:7.770287629682571e-05 max memory_allocated 9912.5283203125 
[2026-01-13 16:13:06 root] (omniquant.py 193): INFO === Start quantize layer 3 ===
[2026-01-13 16:13:12 root] (omniquant.py 274): INFO layer 3 iter 0 loss:0.008837582543492317 norm:8.233274274971336e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:16 root] (omniquant.py 274): INFO layer 3 iter 1 loss:0.008843124844133854 norm:8.326961687998846e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:21 root] (omniquant.py 274): INFO layer 3 iter 2 loss:0.008854379877448082 norm:8.406390406889841e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:25 root] (omniquant.py 274): INFO layer 3 iter 3 loss:0.008858518674969673 norm:8.471961336908862e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:29 root] (omniquant.py 274): INFO layer 3 iter 4 loss:0.008856532163918018 norm:8.541328134015203e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:34 root] (omniquant.py 274): INFO layer 3 iter 5 loss:0.008854017592966557 norm:8.504200377501547e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:39 root] (omniquant.py 274): INFO layer 3 iter 6 loss:0.008849265053868294 norm:8.44018068164587e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:43 root] (omniquant.py 274): INFO layer 3 iter 7 loss:0.008848369121551514 norm:8.446080755675212e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:47 root] (omniquant.py 274): INFO layer 3 iter 8 loss:0.008837617002427578 norm:8.333130972459912e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:52 root] (omniquant.py 274): INFO layer 3 iter 9 loss:0.00882839597761631 norm:8.276345033664256e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:13:56 root] (omniquant.py 274): INFO layer 3 iter 10 loss:0.008825340308248997 norm:8.288519165944308e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:01 root] (omniquant.py 274): INFO layer 3 iter 11 loss:0.008827989920973778 norm:8.322511712322012e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:05 root] (omniquant.py 274): INFO layer 3 iter 12 loss:0.008826866745948792 norm:8.347771654371172e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:10 root] (omniquant.py 274): INFO layer 3 iter 13 loss:0.008822700008749962 norm:8.33461235743016e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:14 root] (omniquant.py 274): INFO layer 3 iter 14 loss:0.008817361667752266 norm:nan max memory_allocated 9913.1611328125 
[2026-01-13 16:14:19 root] (omniquant.py 274): INFO layer 3 iter 15 loss:0.008816963993012905 norm:nan max memory_allocated 9913.1611328125 
[2026-01-13 16:14:23 root] (omniquant.py 274): INFO layer 3 iter 16 loss:0.008819212205708027 norm:nan max memory_allocated 9913.1611328125 
[2026-01-13 16:14:27 root] (omniquant.py 274): INFO layer 3 iter 17 loss:0.008822239004075527 norm:8.088941831374541e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:32 root] (omniquant.py 274): INFO layer 3 iter 18 loss:0.008821344934403896 norm:8.026661089388654e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:36 root] (omniquant.py 274): INFO layer 3 iter 19 loss:0.00882062315940857 norm:8.095973316812888e-05 max memory_allocated 9913.1611328125 
[2026-01-13 16:14:38 root] (omniquant.py 193): INFO === Start quantize layer 4 ===
[2026-01-13 16:14:43 root] (omniquant.py 274): INFO layer 4 iter 0 loss:0.010065453127026558 norm:5.8620615163818e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:14:48 root] (omniquant.py 274): INFO layer 4 iter 1 loss:0.010067526251077652 norm:5.8650632126955315e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:14:52 root] (omniquant.py 274): INFO layer 4 iter 2 loss:0.010073183104395866 norm:6.000182474963367e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:14:57 root] (omniquant.py 274): INFO layer 4 iter 3 loss:0.010066734626889229 norm:6.077572834328748e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:01 root] (omniquant.py 274): INFO layer 4 iter 4 loss:0.010066254064440727 norm:6.094834679970518e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:06 root] (omniquant.py 274): INFO layer 4 iter 5 loss:0.010061420500278473 norm:6.0356960602803156e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:10 root] (omniquant.py 274): INFO layer 4 iter 6 loss:0.01006220281124115 norm:6.0737147578038275e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:15 root] (omniquant.py 274): INFO layer 4 iter 7 loss:0.010071645490825176 norm:6.256623601075262e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:19 root] (omniquant.py 274): INFO layer 4 iter 8 loss:0.010076580569148064 norm:6.337663944577798e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:24 root] (omniquant.py 274): INFO layer 4 iter 9 loss:0.010075649246573448 norm:6.260159716475755e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:29 root] (omniquant.py 274): INFO layer 4 iter 10 loss:0.01007981039583683 norm:6.182137440191582e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:33 root] (omniquant.py 274): INFO layer 4 iter 11 loss:0.010077490471303463 norm:6.0819569625891745e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:38 root] (omniquant.py 274): INFO layer 4 iter 12 loss:0.010076386854052544 norm:6.0685735661536455e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:42 root] (omniquant.py 274): INFO layer 4 iter 13 loss:0.010074542835354805 norm:5.985722236800939e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:47 root] (omniquant.py 274): INFO layer 4 iter 14 loss:0.0100718317553401 norm:5.909035462536849e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:51 root] (omniquant.py 274): INFO layer 4 iter 15 loss:0.010066729970276356 norm:5.860407691216096e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:15:56 root] (omniquant.py 274): INFO layer 4 iter 16 loss:0.01006597001105547 norm:5.9437388699734583e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:16:00 root] (omniquant.py 274): INFO layer 4 iter 17 loss:0.0100625678896904 norm:5.922234049648978e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:16:05 root] (omniquant.py 274): INFO layer 4 iter 18 loss:0.010056532919406891 norm:5.907472223043442e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:16:09 root] (omniquant.py 274): INFO layer 4 iter 19 loss:0.010056370869278908 norm:5.924305150983855e-05 max memory_allocated 9913.7939453125 
[2026-01-13 16:16:11 root] (omniquant.py 193): INFO === Start quantize layer 5 ===
[2026-01-13 16:16:16 root] (omniquant.py 274): INFO layer 5 iter 0 loss:0.011190198361873627 norm:3.1289928301703185e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:21 root] (omniquant.py 274): INFO layer 5 iter 1 loss:0.011186646297574043 norm:3.108358578174375e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:25 root] (omniquant.py 274): INFO layer 5 iter 2 loss:0.01118379645049572 norm:3.112464401056059e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:30 root] (omniquant.py 274): INFO layer 5 iter 3 loss:0.01117767859250307 norm:3.0916158721083775e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:35 root] (omniquant.py 274): INFO layer 5 iter 4 loss:0.011176567524671555 norm:3.0654406145913526e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:39 root] (omniquant.py 274): INFO layer 5 iter 5 loss:0.01117623783648014 norm:3.0797622457612306e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:44 root] (omniquant.py 274): INFO layer 5 iter 6 loss:0.01117499265819788 norm:3.066790304728784e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:48 root] (omniquant.py 274): INFO layer 5 iter 7 loss:0.011170333251357079 norm:3.093805935350247e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:52 root] (omniquant.py 274): INFO layer 5 iter 8 loss:0.011165929958224297 norm:3.163534711347893e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:16:57 root] (omniquant.py 274): INFO layer 5 iter 9 loss:0.011163676157593727 norm:3.154503428959288e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:01 root] (omniquant.py 274): INFO layer 5 iter 10 loss:0.0111593222245574 norm:3.1369923817692325e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:05 root] (omniquant.py 274): INFO layer 5 iter 11 loss:0.011156946420669556 norm:3.104308052570559e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:10 root] (omniquant.py 274): INFO layer 5 iter 12 loss:0.011155597865581512 norm:3.1049716199049726e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:14 root] (omniquant.py 274): INFO layer 5 iter 13 loss:0.011152176186442375 norm:3.1025901989778504e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:19 root] (omniquant.py 274): INFO layer 5 iter 14 loss:0.011150307953357697 norm:3.089819074375555e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:23 root] (omniquant.py 274): INFO layer 5 iter 15 loss:0.011149929836392403 norm:3.102107439190149e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:28 root] (omniquant.py 274): INFO layer 5 iter 16 loss:0.011148972436785698 norm:3.0965005862526596e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:32 root] (omniquant.py 274): INFO layer 5 iter 17 loss:0.011148407123982906 norm:3.101171023445204e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:36 root] (omniquant.py 274): INFO layer 5 iter 18 loss:0.011147703975439072 norm:3.1255367503035814e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:41 root] (omniquant.py 274): INFO layer 5 iter 19 loss:0.011145821772515774 norm:3.134168582619168e-05 max memory_allocated 9914.4267578125 
[2026-01-13 16:17:42 root] (omniquant.py 193): INFO === Start quantize layer 6 ===
[2026-01-13 16:17:47 root] (omniquant.py 274): INFO layer 6 iter 0 loss:0.012628231197595596 norm:4.762573735206388e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:17:52 root] (omniquant.py 274): INFO layer 6 iter 1 loss:0.012624501250684261 norm:4.760357114719227e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:17:56 root] (omniquant.py 274): INFO layer 6 iter 2 loss:0.01262682769447565 norm:4.7375775466207415e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:01 root] (omniquant.py 274): INFO layer 6 iter 3 loss:0.012628735043108463 norm:4.728186104330234e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:05 root] (omniquant.py 274): INFO layer 6 iter 4 loss:0.012629600241780281 norm:4.713093949249014e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:10 root] (omniquant.py 274): INFO layer 6 iter 5 loss:0.012628655880689621 norm:4.680267738876864e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:14 root] (omniquant.py 274): INFO layer 6 iter 6 loss:0.012628662399947643 norm:4.722378798760474e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:18 root] (omniquant.py 274): INFO layer 6 iter 7 loss:0.01263018511235714 norm:4.7007495595607907e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:23 root] (omniquant.py 274): INFO layer 6 iter 8 loss:0.01263112761080265 norm:4.694947710959241e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:27 root] (omniquant.py 274): INFO layer 6 iter 9 loss:0.012634962797164917 norm:4.75322303827852e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:32 root] (omniquant.py 274): INFO layer 6 iter 10 loss:0.012635434046387672 norm:4.744725811178796e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:36 root] (omniquant.py 274): INFO layer 6 iter 11 loss:0.012636370025575161 norm:4.770311352331191e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:41 root] (omniquant.py 274): INFO layer 6 iter 12 loss:0.01263762079179287 norm:4.752723179990426e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:46 root] (omniquant.py 274): INFO layer 6 iter 13 loss:0.01263952162116766 norm:4.784853081218898e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:50 root] (omniquant.py 274): INFO layer 6 iter 14 loss:0.0126457205042243 norm:4.968901339452714e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:54 root] (omniquant.py 274): INFO layer 6 iter 15 loss:0.012647866271436214 norm:5.018021693103947e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:18:59 root] (omniquant.py 274): INFO layer 6 iter 16 loss:0.012645245529711246 norm:5.003312980988994e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:19:03 root] (omniquant.py 274): INFO layer 6 iter 17 loss:0.01264435425400734 norm:4.952414383296855e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:19:07 root] (omniquant.py 274): INFO layer 6 iter 18 loss:0.012643901631236076 norm:4.8868401790969074e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:19:12 root] (omniquant.py 274): INFO layer 6 iter 19 loss:0.012645703740417957 norm:4.856132363784127e-05 max memory_allocated 9915.0595703125 
[2026-01-13 16:19:13 root] (omniquant.py 193): INFO === Start quantize layer 7 ===
[2026-01-13 16:19:19 root] (omniquant.py 274): INFO layer 7 iter 0 loss:0.014300853945314884 norm:8.302560308948159e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:23 root] (omniquant.py 274): INFO layer 7 iter 1 loss:0.014297716319561005 norm:8.283228089567274e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:28 root] (omniquant.py 274): INFO layer 7 iter 2 loss:0.014298371970653534 norm:8.189793879864737e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:32 root] (omniquant.py 274): INFO layer 7 iter 3 loss:0.014295232482254505 norm:8.106207678792998e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:37 root] (omniquant.py 274): INFO layer 7 iter 4 loss:0.014293326064944267 norm:8.053152123466134e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:41 root] (omniquant.py 274): INFO layer 7 iter 5 loss:0.014294710010290146 norm:7.980653026606888e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:45 root] (omniquant.py 274): INFO layer 7 iter 6 loss:0.014297755435109138 norm:7.877770985942334e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:50 root] (omniquant.py 274): INFO layer 7 iter 7 loss:0.014298317953944206 norm:7.838323654141277e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:54 root] (omniquant.py 274): INFO layer 7 iter 8 loss:0.01429690606892109 norm:7.849897519918159e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:19:59 root] (omniquant.py 274): INFO layer 7 iter 9 loss:0.014297041110694408 norm:7.876293238950893e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:03 root] (omniquant.py 274): INFO layer 7 iter 10 loss:0.014296079985797405 norm:7.820613973308355e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:07 root] (omniquant.py 274): INFO layer 7 iter 11 loss:0.014295317232608795 norm:7.787701179040596e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:12 root] (omniquant.py 274): INFO layer 7 iter 12 loss:0.014296537265181541 norm:7.81121852924116e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:16 root] (omniquant.py 274): INFO layer 7 iter 13 loss:0.014298566617071629 norm:7.909366104286164e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:21 root] (omniquant.py 274): INFO layer 7 iter 14 loss:0.014293842017650604 norm:7.888958498369902e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:25 root] (omniquant.py 274): INFO layer 7 iter 15 loss:0.014291249215602875 norm:7.916353206383064e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:30 root] (omniquant.py 274): INFO layer 7 iter 16 loss:0.01428715605288744 norm:7.909310079412535e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:34 root] (omniquant.py 274): INFO layer 7 iter 17 loss:0.014286471530795097 norm:7.97539105406031e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:39 root] (omniquant.py 274): INFO layer 7 iter 18 loss:0.01428811065852642 norm:8.010990859474987e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:43 root] (omniquant.py 274): INFO layer 7 iter 19 loss:0.014294016174972057 norm:8.033236372284591e-05 max memory_allocated 9915.6923828125 
[2026-01-13 16:20:44 root] (omniquant.py 193): INFO === Start quantize layer 8 ===
[2026-01-13 16:20:50 root] (omniquant.py 274): INFO layer 8 iter 0 loss:0.015483375638723373 norm:8.582069131080061e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:20:55 root] (omniquant.py 274): INFO layer 8 iter 1 loss:0.015478724613785744 norm:8.499807881889865e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:20:59 root] (omniquant.py 274): INFO layer 8 iter 2 loss:0.015483110211789608 norm:8.54072131915018e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:04 root] (omniquant.py 274): INFO layer 8 iter 3 loss:0.015487678349018097 norm:8.608394273323938e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:08 root] (omniquant.py 274): INFO layer 8 iter 4 loss:0.015489323064684868 norm:8.585234172642231e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:13 root] (omniquant.py 274): INFO layer 8 iter 5 loss:0.015490273013710976 norm:8.583049202570692e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:17 root] (omniquant.py 274): INFO layer 8 iter 6 loss:0.015488168224692345 norm:8.581096335547045e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:21 root] (omniquant.py 274): INFO layer 8 iter 7 loss:0.015487554483115673 norm:8.677713049110025e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:26 root] (omniquant.py 274): INFO layer 8 iter 8 loss:0.015495097264647484 norm:8.799896750133485e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:31 root] (omniquant.py 274): INFO layer 8 iter 9 loss:0.015493519604206085 norm:8.763725782046095e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:35 root] (omniquant.py 274): INFO layer 8 iter 10 loss:0.01549507211893797 norm:8.855087799020112e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:40 root] (omniquant.py 274): INFO layer 8 iter 11 loss:0.015496534295380116 norm:8.95592020242475e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:44 root] (omniquant.py 274): INFO layer 8 iter 12 loss:0.015496710315346718 norm:8.916817023418844e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:49 root] (omniquant.py 274): INFO layer 8 iter 13 loss:0.015499427914619446 norm:8.911001350497827e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:53 root] (omniquant.py 274): INFO layer 8 iter 14 loss:0.015498820692300797 norm:8.834001346258447e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:21:58 root] (omniquant.py 274): INFO layer 8 iter 15 loss:0.015496429055929184 norm:8.78842402016744e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:22:02 root] (omniquant.py 274): INFO layer 8 iter 16 loss:0.015499209985136986 norm:8.774694288149476e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:22:07 root] (omniquant.py 274): INFO layer 8 iter 17 loss:0.015500003471970558 norm:8.706566586624831e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:22:12 root] (omniquant.py 274): INFO layer 8 iter 18 loss:0.015499399043619633 norm:8.627125498605892e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:22:16 root] (omniquant.py 274): INFO layer 8 iter 19 loss:0.015498895198106766 norm:8.59551364555955e-05 max memory_allocated 9916.3251953125 
[2026-01-13 16:22:17 root] (omniquant.py 193): INFO === Start quantize layer 9 ===
[2026-01-13 16:22:23 root] (omniquant.py 274): INFO layer 9 iter 0 loss:0.01732211373746395 norm:7.295757677638903e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:27 root] (omniquant.py 274): INFO layer 9 iter 1 loss:0.017318306490778923 norm:7.248228212120011e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:32 root] (omniquant.py 274): INFO layer 9 iter 2 loss:0.017315534874796867 norm:7.203537825262174e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:36 root] (omniquant.py 274): INFO layer 9 iter 3 loss:0.017304273322224617 norm:7.215162622742355e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:41 root] (omniquant.py 274): INFO layer 9 iter 4 loss:0.01728639379143715 norm:7.21349788364023e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:45 root] (omniquant.py 274): INFO layer 9 iter 5 loss:0.017290819436311722 norm:7.196794467745349e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:49 root] (omniquant.py 274): INFO layer 9 iter 6 loss:0.017290305346250534 norm:7.18606825103052e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:54 root] (omniquant.py 274): INFO layer 9 iter 7 loss:0.01728539541363716 norm:7.162393012549728e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:22:59 root] (omniquant.py 274): INFO layer 9 iter 8 loss:0.01728283055126667 norm:7.122839451767504e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:03 root] (omniquant.py 274): INFO layer 9 iter 9 loss:0.01728462427854538 norm:7.159171946113929e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:08 root] (omniquant.py 274): INFO layer 9 iter 10 loss:0.017282266169786453 norm:7.143808761611581e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:12 root] (omniquant.py 274): INFO layer 9 iter 11 loss:0.017280248925089836 norm:7.136112253647298e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:17 root] (omniquant.py 274): INFO layer 9 iter 12 loss:0.01728510670363903 norm:7.120474037947133e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:21 root] (omniquant.py 274): INFO layer 9 iter 13 loss:0.017285697162151337 norm:7.048137194942683e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:26 root] (omniquant.py 274): INFO layer 9 iter 14 loss:0.017286773771047592 norm:7.05970887793228e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:30 root] (omniquant.py 274): INFO layer 9 iter 15 loss:0.017274294048547745 norm:6.993265560595319e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:35 root] (omniquant.py 274): INFO layer 9 iter 16 loss:0.017264075577259064 norm:6.981086335144937e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:39 root] (omniquant.py 274): INFO layer 9 iter 17 loss:0.017260823398828506 norm:6.983338971622288e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:44 root] (omniquant.py 274): INFO layer 9 iter 18 loss:0.017253056168556213 norm:6.962591578485444e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:48 root] (omniquant.py 274): INFO layer 9 iter 19 loss:0.017244305461645126 norm:6.982145714573562e-05 max memory_allocated 9916.9580078125 
[2026-01-13 16:23:50 root] (omniquant.py 193): INFO === Start quantize layer 10 ===
[2026-01-13 16:23:55 root] (omniquant.py 274): INFO layer 10 iter 0 loss:0.01978682167828083 norm:0.00013291787763591856 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:00 root] (omniquant.py 274): INFO layer 10 iter 1 loss:0.019780900329351425 norm:0.0001326754136243835 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:04 root] (omniquant.py 274): INFO layer 10 iter 2 loss:0.01975981704890728 norm:0.0001310879597440362 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:09 root] (omniquant.py 274): INFO layer 10 iter 3 loss:0.019749965518712997 norm:0.0001312397071160376 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:13 root] (omniquant.py 274): INFO layer 10 iter 4 loss:0.01975487545132637 norm:0.00013160101661924273 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:18 root] (omniquant.py 274): INFO layer 10 iter 5 loss:0.019754238426685333 norm:0.00013130476872902364 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:22 root] (omniquant.py 274): INFO layer 10 iter 6 loss:0.019750699400901794 norm:0.00013137731002643704 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:27 root] (omniquant.py 274): INFO layer 10 iter 7 loss:0.019755346700549126 norm:0.00013171197497285903 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:32 root] (omniquant.py 274): INFO layer 10 iter 8 loss:0.019761087372899055 norm:0.00013200812099967152 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:36 root] (omniquant.py 274): INFO layer 10 iter 9 loss:0.019758790731430054 norm:0.00013214163482189178 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:41 root] (omniquant.py 274): INFO layer 10 iter 10 loss:0.019749077036976814 norm:0.0001314966648351401 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:45 root] (omniquant.py 274): INFO layer 10 iter 11 loss:0.019756022840738297 norm:0.00013158554793335497 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:50 root] (omniquant.py 274): INFO layer 10 iter 12 loss:0.019732892513275146 norm:0.00013123781536705792 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:54 root] (omniquant.py 274): INFO layer 10 iter 13 loss:0.019729364663362503 norm:0.00013097452756483108 max memory_allocated 9917.5908203125 
[2026-01-13 16:24:59 root] (omniquant.py 274): INFO layer 10 iter 14 loss:0.019730689004063606 norm:0.00013026586384512484 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:03 root] (omniquant.py 274): INFO layer 10 iter 15 loss:0.01973983459174633 norm:0.0001300615695072338 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:07 root] (omniquant.py 274): INFO layer 10 iter 16 loss:0.019748074933886528 norm:0.0001302484015468508 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:12 root] (omniquant.py 274): INFO layer 10 iter 17 loss:0.019743863493204117 norm:0.00012992038682568818 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:17 root] (omniquant.py 274): INFO layer 10 iter 18 loss:0.0197317935526371 norm:0.0001295048277825117 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:21 root] (omniquant.py 274): INFO layer 10 iter 19 loss:0.01971336081624031 norm:0.00012846551544498652 max memory_allocated 9917.5908203125 
[2026-01-13 16:25:22 root] (omniquant.py 193): INFO === Start quantize layer 11 ===
[2026-01-13 16:25:28 root] (omniquant.py 274): INFO layer 11 iter 0 loss:0.021839793771505356 norm:0.00015714656910859048 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:32 root] (omniquant.py 274): INFO layer 11 iter 1 loss:0.021824810653924942 norm:0.00015663680096622556 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:37 root] (omniquant.py 274): INFO layer 11 iter 2 loss:0.02183099463582039 norm:0.00015680206706747413 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:41 root] (omniquant.py 274): INFO layer 11 iter 3 loss:0.021846087649464607 norm:0.00015728057769592851 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:46 root] (omniquant.py 274): INFO layer 11 iter 4 loss:0.021839382126927376 norm:0.00015753068146295846 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:50 root] (omniquant.py 274): INFO layer 11 iter 5 loss:0.02183828130364418 norm:0.00015803283895365894 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:55 root] (omniquant.py 274): INFO layer 11 iter 6 loss:0.02183328941464424 norm:0.00015671606524847448 max memory_allocated 9918.2236328125 
[2026-01-13 16:25:59 root] (omniquant.py 274): INFO layer 11 iter 7 loss:0.02182927168905735 norm:0.00015699838695582002 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:04 root] (omniquant.py 274): INFO layer 11 iter 8 loss:0.02183440513908863 norm:0.00015657786570955068 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:08 root] (omniquant.py 274): INFO layer 11 iter 9 loss:0.021847927942872047 norm:0.00015579791215714067 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:13 root] (omniquant.py 274): INFO layer 11 iter 10 loss:0.021830378100275993 norm:0.00015454358072020113 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:18 root] (omniquant.py 274): INFO layer 11 iter 11 loss:0.02183210477232933 norm:0.00015532375255133957 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:22 root] (omniquant.py 274): INFO layer 11 iter 12 loss:0.021839821711182594 norm:0.00015626470849383622 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:27 root] (omniquant.py 274): INFO layer 11 iter 13 loss:0.02185138314962387 norm:0.00015688189887441695 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:31 root] (omniquant.py 274): INFO layer 11 iter 14 loss:0.021859247237443924 norm:0.00015506740601267666 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:36 root] (omniquant.py 274): INFO layer 11 iter 15 loss:0.021864425390958786 norm:0.0001536961499368772 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:40 root] (omniquant.py 274): INFO layer 11 iter 16 loss:0.021855955943465233 norm:0.00015371391782537103 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:45 root] (omniquant.py 274): INFO layer 11 iter 17 loss:0.02183014154434204 norm:0.00015252183948177844 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:49 root] (omniquant.py 274): INFO layer 11 iter 18 loss:0.021820953115820885 norm:0.00015165504009928554 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:53 root] (omniquant.py 274): INFO layer 11 iter 19 loss:0.021823536604642868 norm:0.0001509068242739886 max memory_allocated 9918.2236328125 
[2026-01-13 16:26:55 root] (omniquant.py 193): INFO === Start quantize layer 12 ===
[2026-01-13 16:27:00 root] (omniquant.py 274): INFO layer 12 iter 0 loss:0.025019213557243347 norm:0.0002355115721002221 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:04 root] (omniquant.py 274): INFO layer 12 iter 1 loss:0.025008032098412514 norm:0.00023438762582372874 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:09 root] (omniquant.py 274): INFO layer 12 iter 2 loss:0.0249490924179554 norm:0.0002282971836393699 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:13 root] (omniquant.py 274): INFO layer 12 iter 3 loss:0.02484237030148506 norm:0.00022173396428115666 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:18 root] (omniquant.py 274): INFO layer 12 iter 4 loss:0.024772148579359055 norm:0.00021827234013471752 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:22 root] (omniquant.py 274): INFO layer 12 iter 5 loss:0.02472558803856373 norm:0.00021582604676950723 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:27 root] (omniquant.py 274): INFO layer 12 iter 6 loss:0.024743618443608284 norm:0.00021292602468747646 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:31 root] (omniquant.py 274): INFO layer 12 iter 7 loss:0.02475246973335743 norm:0.00021113452385179698 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:35 root] (omniquant.py 274): INFO layer 12 iter 8 loss:0.024689799174666405 norm:0.00020869493891950697 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:40 root] (omniquant.py 274): INFO layer 12 iter 9 loss:0.024718426167964935 norm:0.00020863133249804378 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:44 root] (omniquant.py 274): INFO layer 12 iter 10 loss:0.024679938331246376 norm:0.00020624877652153373 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:49 root] (omniquant.py 274): INFO layer 12 iter 11 loss:0.024651704356074333 norm:0.0002045718429144472 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:53 root] (omniquant.py 274): INFO layer 12 iter 12 loss:0.024684682488441467 norm:0.00020424739341251552 max memory_allocated 9918.8564453125 
[2026-01-13 16:27:57 root] (omniquant.py 274): INFO layer 12 iter 13 loss:0.024669717997312546 norm:0.00020296379807405174 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:02 root] (omniquant.py 274): INFO layer 12 iter 14 loss:0.024654297158122063 norm:0.00020228033827152103 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:06 root] (omniquant.py 274): INFO layer 12 iter 15 loss:0.024696040898561478 norm:0.00020184421737212688 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:10 root] (omniquant.py 274): INFO layer 12 iter 16 loss:0.02468525618314743 norm:0.00020220156875438988 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:15 root] (omniquant.py 274): INFO layer 12 iter 17 loss:0.024661758914589882 norm:0.00020150993077550083 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:20 root] (omniquant.py 274): INFO layer 12 iter 18 loss:0.02465139515697956 norm:0.0002003736881306395 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:24 root] (omniquant.py 274): INFO layer 12 iter 19 loss:0.024620868265628815 norm:0.0001998569059651345 max memory_allocated 9918.8564453125 
[2026-01-13 16:28:26 root] (omniquant.py 193): INFO === Start quantize layer 13 ===
[2026-01-13 16:28:32 root] (omniquant.py 274): INFO layer 13 iter 0 loss:0.02789543755352497 norm:0.00018763869593385607 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:36 root] (omniquant.py 274): INFO layer 13 iter 1 loss:0.027915818616747856 norm:0.00018829332839231938 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:40 root] (omniquant.py 274): INFO layer 13 iter 2 loss:0.027924632653594017 norm:0.00018858388648368418 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:45 root] (omniquant.py 274): INFO layer 13 iter 3 loss:0.02791867032647133 norm:0.00018804932187777013 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:49 root] (omniquant.py 274): INFO layer 13 iter 4 loss:0.027934815734624863 norm:0.00018888154590968043 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:54 root] (omniquant.py 274): INFO layer 13 iter 5 loss:0.027919601649045944 norm:0.00018872924556490034 max memory_allocated 9919.4892578125 
[2026-01-13 16:28:58 root] (omniquant.py 274): INFO layer 13 iter 6 loss:0.027907133102416992 norm:0.0001877661852631718 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:03 root] (omniquant.py 274): INFO layer 13 iter 7 loss:0.02791249379515648 norm:0.00018753361655399203 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:07 root] (omniquant.py 274): INFO layer 13 iter 8 loss:0.027921875938773155 norm:0.00018819182878360152 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:12 root] (omniquant.py 274): INFO layer 13 iter 9 loss:0.027927443385124207 norm:0.00018894061213359237 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:16 root] (omniquant.py 274): INFO layer 13 iter 10 loss:0.02793038822710514 norm:0.00018906607874669135 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:20 root] (omniquant.py 274): INFO layer 13 iter 11 loss:0.027939043939113617 norm:0.00018947443459182978 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:25 root] (omniquant.py 274): INFO layer 13 iter 12 loss:0.027923164889216423 norm:0.000188996025826782 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:29 root] (omniquant.py 274): INFO layer 13 iter 13 loss:0.02789030596613884 norm:0.00018666779214981943 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:34 root] (omniquant.py 274): INFO layer 13 iter 14 loss:0.027894895523786545 norm:0.00018522454774938524 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:38 root] (omniquant.py 274): INFO layer 13 iter 15 loss:0.02787918969988823 norm:0.0001860097690951079 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:43 root] (omniquant.py 274): INFO layer 13 iter 16 loss:0.027849974110722542 norm:0.00018600770272314548 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:47 root] (omniquant.py 274): INFO layer 13 iter 17 loss:0.027805065736174583 norm:0.00018537828873377293 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:51 root] (omniquant.py 274): INFO layer 13 iter 18 loss:0.027771729975938797 norm:0.00018410060147289187 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:56 root] (omniquant.py 274): INFO layer 13 iter 19 loss:0.027765564620494843 norm:0.00018402727437205613 max memory_allocated 9919.4892578125 
[2026-01-13 16:29:57 root] (omniquant.py 193): INFO === Start quantize layer 14 ===
[2026-01-13 16:30:03 root] (omniquant.py 274): INFO layer 14 iter 0 loss:0.030763782560825348 norm:0.00021674533491022885 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:07 root] (omniquant.py 274): INFO layer 14 iter 1 loss:0.030714992433786392 norm:0.0002158543939003721 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:12 root] (omniquant.py 274): INFO layer 14 iter 2 loss:0.03069230541586876 norm:0.0002143686724593863 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:16 root] (omniquant.py 274): INFO layer 14 iter 3 loss:0.030675992369651794 norm:0.00021357765945140272 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:20 root] (omniquant.py 274): INFO layer 14 iter 4 loss:0.0306538138538599 norm:0.0002129772474290803 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:25 root] (omniquant.py 274): INFO layer 14 iter 5 loss:0.030648499727249146 norm:0.00021207481040619314 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:29 root] (omniquant.py 274): INFO layer 14 iter 6 loss:0.030644390732049942 norm:0.00021120697783771902 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:34 root] (omniquant.py 274): INFO layer 14 iter 7 loss:0.0306365005671978 norm:0.0002107723121298477 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:38 root] (omniquant.py 274): INFO layer 14 iter 8 loss:0.030638953670859337 norm:0.00021073105745017529 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:42 root] (omniquant.py 274): INFO layer 14 iter 9 loss:0.030640538781881332 norm:0.00020985690935049206 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:47 root] (omniquant.py 274): INFO layer 14 iter 10 loss:0.030642181634902954 norm:0.0002095536474371329 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:51 root] (omniquant.py 274): INFO layer 14 iter 11 loss:0.03064635768532753 norm:0.00020797904289793223 max memory_allocated 9920.1220703125 
[2026-01-13 16:30:56 root] (omniquant.py 274): INFO layer 14 iter 12 loss:0.03062845952808857 norm:0.00020763574866577983 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:00 root] (omniquant.py 274): INFO layer 14 iter 13 loss:0.03061148338019848 norm:0.00020776221936102957 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:04 root] (omniquant.py 274): INFO layer 14 iter 14 loss:0.03059513121843338 norm:0.00020620446593966335 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:09 root] (omniquant.py 274): INFO layer 14 iter 15 loss:0.030585413798689842 norm:0.00020555262744892389 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:13 root] (omniquant.py 274): INFO layer 14 iter 16 loss:0.03059750236570835 norm:0.00020501027756836265 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:18 root] (omniquant.py 274): INFO layer 14 iter 17 loss:0.03059423714876175 norm:0.00020327481615822762 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:22 root] (omniquant.py 274): INFO layer 14 iter 18 loss:0.030614595860242844 norm:0.0002025532885454595 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:27 root] (omniquant.py 274): INFO layer 14 iter 19 loss:0.03065355494618416 norm:0.00020246213534846902 max memory_allocated 9920.1220703125 
[2026-01-13 16:31:28 root] (omniquant.py 193): INFO === Start quantize layer 15 ===
[2026-01-13 16:31:33 root] (omniquant.py 274): INFO layer 15 iter 0 loss:0.03832477331161499 norm:0.000637620803900063 max memory_allocated 9920.7548828125 
[2026-01-13 16:31:38 root] (omniquant.py 274): INFO layer 15 iter 1 loss:0.03827700391411781 norm:0.0006346128648146987 max memory_allocated 9920.7548828125 
[2026-01-13 16:31:42 root] (omniquant.py 274): INFO layer 15 iter 2 loss:0.03820277377963066 norm:0.0006313225021585822 max memory_allocated 9920.7548828125 
[2026-01-13 16:31:47 root] (omniquant.py 274): INFO layer 15 iter 3 loss:0.03826195374131203 norm:0.0006343027343973517 max memory_allocated 9920.7548828125 
[2026-01-13 16:31:51 root] (omniquant.py 274): INFO layer 15 iter 4 loss:0.038226861506700516 norm:0.0006310652242973447 max memory_allocated 9920.7548828125 
[2026-01-13 16:31:56 root] (omniquant.py 274): INFO layer 15 iter 5 loss:0.03817557916045189 norm:0.0006334694917313755 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:00 root] (omniquant.py 274): INFO layer 15 iter 6 loss:0.0381145216524601 norm:0.0006314439815469086 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:05 root] (omniquant.py 274): INFO layer 15 iter 7 loss:0.03813118860125542 norm:0.0006313668563961983 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:09 root] (omniquant.py 274): INFO layer 15 iter 8 loss:0.0381302535533905 norm:0.0006314906058833003 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:14 root] (omniquant.py 274): INFO layer 15 iter 9 loss:0.03815896809101105 norm:0.0006275581545196474 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:18 root] (omniquant.py 274): INFO layer 15 iter 10 loss:0.038053106516599655 norm:0.0006172154098749161 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:23 root] (omniquant.py 274): INFO layer 15 iter 11 loss:0.03804817423224449 norm:0.0006133058341220021 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:27 root] (omniquant.py 274): INFO layer 15 iter 12 loss:0.03796803578734398 norm:0.0006093232077546418 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:31 root] (omniquant.py 274): INFO layer 15 iter 13 loss:0.03795621544122696 norm:0.0006074883276596665 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:36 root] (omniquant.py 274): INFO layer 15 iter 14 loss:0.037918224930763245 norm:0.0006012002704665065 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:41 root] (omniquant.py 274): INFO layer 15 iter 15 loss:0.03789980337023735 norm:0.0005949662299826741 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:45 root] (omniquant.py 274): INFO layer 15 iter 16 loss:0.037852197885513306 norm:0.00059266178868711 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:50 root] (omniquant.py 274): INFO layer 15 iter 17 loss:0.03781357780098915 norm:0.0005940601695328951 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:54 root] (omniquant.py 274): INFO layer 15 iter 18 loss:0.03779388964176178 norm:0.000593004166148603 max memory_allocated 9920.7548828125 
[2026-01-13 16:32:59 root] (omniquant.py 274): INFO layer 15 iter 19 loss:0.03775174915790558 norm:0.0005890205502510071 max memory_allocated 9920.7548828125 
[2026-01-13 16:33:00 root] (omniquant.py 193): INFO === Start quantize layer 16 ===
[2026-01-13 16:33:05 root] (omniquant.py 274): INFO layer 16 iter 0 loss:0.044292837381362915 norm:0.0003639319911599159 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:10 root] (omniquant.py 274): INFO layer 16 iter 1 loss:0.04427233338356018 norm:0.0003617868642322719 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:14 root] (omniquant.py 274): INFO layer 16 iter 2 loss:0.044249873608350754 norm:0.00036115082912147045 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:18 root] (omniquant.py 274): INFO layer 16 iter 3 loss:0.0442059151828289 norm:0.00035988030140288174 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:22 root] (omniquant.py 274): INFO layer 16 iter 4 loss:0.04414777830243111 norm:0.00035759760066866875 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:27 root] (omniquant.py 274): INFO layer 16 iter 5 loss:0.04408448189496994 norm:0.0003546751104295254 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:31 root] (omniquant.py 274): INFO layer 16 iter 6 loss:0.044087186455726624 norm:0.000353766925400123 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:36 root] (omniquant.py 274): INFO layer 16 iter 7 loss:0.04410110414028168 norm:0.0003518050943966955 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:40 root] (omniquant.py 274): INFO layer 16 iter 8 loss:0.04409218579530716 norm:0.0003518939483910799 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:44 root] (omniquant.py 274): INFO layer 16 iter 9 loss:0.044089097529649734 norm:0.0003517160948831588 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:49 root] (omniquant.py 274): INFO layer 16 iter 10 loss:0.04402121901512146 norm:0.00034894546843133867 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:53 root] (omniquant.py 274): INFO layer 16 iter 11 loss:0.04400724172592163 norm:0.0003480849554762244 max memory_allocated 9921.3876953125 
[2026-01-13 16:33:58 root] (omniquant.py 274): INFO layer 16 iter 12 loss:0.04398370534181595 norm:0.0003481021267361939 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:02 root] (omniquant.py 274): INFO layer 16 iter 13 loss:0.043942999094724655 norm:0.0003462262684479356 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:07 root] (omniquant.py 274): INFO layer 16 iter 14 loss:0.04392756521701813 norm:0.0003452568198554218 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:11 root] (omniquant.py 274): INFO layer 16 iter 15 loss:0.043911293148994446 norm:0.00034559034975245595 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:15 root] (omniquant.py 274): INFO layer 16 iter 16 loss:0.04392938315868378 norm:0.00034557926119305193 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:19 root] (omniquant.py 274): INFO layer 16 iter 17 loss:0.043943196535110474 norm:0.00034587839036248624 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:24 root] (omniquant.py 274): INFO layer 16 iter 18 loss:0.04395325854420662 norm:0.00034596642944961786 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:29 root] (omniquant.py 274): INFO layer 16 iter 19 loss:0.044027116149663925 norm:0.00034714178764261305 max memory_allocated 9921.3876953125 
[2026-01-13 16:34:30 root] (omniquant.py 193): INFO === Start quantize layer 17 ===
[2026-01-13 16:34:35 root] (omniquant.py 274): INFO layer 17 iter 0 loss:0.05512438714504242 norm:0.0005319949705153704 max memory_allocated 9922.0205078125 
[2026-01-13 16:34:40 root] (omniquant.py 274): INFO layer 17 iter 1 loss:0.05513439700007439 norm:0.0005294162547215819 max memory_allocated 9922.0205078125 
[2026-01-13 16:34:44 root] (omniquant.py 274): INFO layer 17 iter 2 loss:0.05510056018829346 norm:0.0005265474901534617 max memory_allocated 9922.0205078125 
[2026-01-13 16:34:49 root] (omniquant.py 274): INFO layer 17 iter 3 loss:0.0550902783870697 norm:0.0005260458565317094 max memory_allocated 9922.0205078125 
[2026-01-13 16:34:53 root] (omniquant.py 274): INFO layer 17 iter 4 loss:0.05509340763092041 norm:0.0005251421825960279 max memory_allocated 9922.0205078125 
[2026-01-13 16:34:57 root] (omniquant.py 274): INFO layer 17 iter 5 loss:0.05505647882819176 norm:0.0005234883283264935 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:02 root] (omniquant.py 274): INFO layer 17 iter 6 loss:0.05505407601594925 norm:0.0005203820765018463 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:06 root] (omniquant.py 274): INFO layer 17 iter 7 loss:0.05501875281333923 norm:0.0005187180358916521 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:11 root] (omniquant.py 274): INFO layer 17 iter 8 loss:0.05499318614602089 norm:0.0005148305208422244 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:15 root] (omniquant.py 274): INFO layer 17 iter 9 loss:0.05501909926533699 norm:0.0005122535512782633 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:19 root] (omniquant.py 274): INFO layer 17 iter 10 loss:0.05501610040664673 norm:0.0005067159072495997 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:24 root] (omniquant.py 274): INFO layer 17 iter 11 loss:0.0550452284514904 norm:0.0005062189302407205 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:28 root] (omniquant.py 274): INFO layer 17 iter 12 loss:0.05505051463842392 norm:0.0005043661803938448 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:33 root] (omniquant.py 274): INFO layer 17 iter 13 loss:0.054977722465991974 norm:0.0005002070683985949 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:37 root] (omniquant.py 274): INFO layer 17 iter 14 loss:0.05497518554329872 norm:0.000499010260682553 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:42 root] (omniquant.py 274): INFO layer 17 iter 15 loss:0.05498223006725311 norm:0.0004963995306752622 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:46 root] (omniquant.py 274): INFO layer 17 iter 16 loss:0.054964542388916016 norm:0.0004964421968907118 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:50 root] (omniquant.py 274): INFO layer 17 iter 17 loss:0.054937899112701416 norm:0.0004962628590874374 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:55 root] (omniquant.py 274): INFO layer 17 iter 18 loss:0.054970577359199524 norm:0.0004965616390109062 max memory_allocated 9922.0205078125 
[2026-01-13 16:35:59 root] (omniquant.py 274): INFO layer 17 iter 19 loss:0.05494379252195358 norm:0.0004975500050932169 max memory_allocated 9922.0205078125 
[2026-01-13 16:36:01 root] (omniquant.py 193): INFO === Start quantize layer 18 ===
[2026-01-13 16:36:06 root] (omniquant.py 274): INFO layer 18 iter 0 loss:0.06521425396203995 norm:0.0007838979363441467 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:10 root] (omniquant.py 274): INFO layer 18 iter 1 loss:0.06523756682872772 norm:0.0007825102657079697 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:15 root] (omniquant.py 274): INFO layer 18 iter 2 loss:0.06524346768856049 norm:0.0007825097418390214 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:19 root] (omniquant.py 274): INFO layer 18 iter 3 loss:0.06526104360818863 norm:0.0007791747921146452 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:24 root] (omniquant.py 274): INFO layer 18 iter 4 loss:0.06528104096651077 norm:0.000777631183154881 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:28 root] (omniquant.py 274): INFO layer 18 iter 5 loss:0.06530947983264923 norm:0.0007720248540863395 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:33 root] (omniquant.py 274): INFO layer 18 iter 6 loss:0.06524769216775894 norm:0.0007716967957094312 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:37 root] (omniquant.py 274): INFO layer 18 iter 7 loss:0.0652053952217102 norm:0.0007722268928773701 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:42 root] (omniquant.py 274): INFO layer 18 iter 8 loss:0.06518487632274628 norm:0.0007748245843686163 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:46 root] (omniquant.py 274): INFO layer 18 iter 9 loss:0.0651613250374794 norm:0.0007745842449367046 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:50 root] (omniquant.py 274): INFO layer 18 iter 10 loss:0.06514248251914978 norm:0.0007765271584503353 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:55 root] (omniquant.py 274): INFO layer 18 iter 11 loss:0.0651770606637001 norm:0.0007777809514664114 max memory_allocated 9922.6533203125 
[2026-01-13 16:36:59 root] (omniquant.py 274): INFO layer 18 iter 12 loss:0.06512653082609177 norm:0.0007734287064522505 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:03 root] (omniquant.py 274): INFO layer 18 iter 13 loss:0.06517735123634338 norm:0.0007720910361967981 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:08 root] (omniquant.py 274): INFO layer 18 iter 14 loss:0.06516235321760178 norm:0.0007711024954915047 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:12 root] (omniquant.py 274): INFO layer 18 iter 15 loss:0.06522172689437866 norm:0.0007644345751032233 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:17 root] (omniquant.py 274): INFO layer 18 iter 16 loss:0.06528347730636597 norm:0.000760245427954942 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:21 root] (omniquant.py 274): INFO layer 18 iter 17 loss:0.0652695745229721 norm:0.0007617712835781276 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:26 root] (omniquant.py 274): INFO layer 18 iter 18 loss:0.06521271169185638 norm:0.0007585844141431153 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:30 root] (omniquant.py 274): INFO layer 18 iter 19 loss:0.06506569683551788 norm:0.0007521118386648595 max memory_allocated 9922.6533203125 
[2026-01-13 16:37:31 root] (omniquant.py 193): INFO === Start quantize layer 19 ===
[2026-01-13 16:37:36 root] (omniquant.py 274): INFO layer 19 iter 0 loss:0.0740073174238205 norm:0.0007599435630254447 max memory_allocated 9923.2861328125 
[2026-01-13 16:37:41 root] (omniquant.py 274): INFO layer 19 iter 1 loss:0.07397449016571045 norm:0.000732632412109524 max memory_allocated 9923.2861328125 
[2026-01-13 16:37:46 root] (omniquant.py 274): INFO layer 19 iter 2 loss:0.07391476631164551 norm:0.0007219591061584651 max memory_allocated 9923.2861328125 
[2026-01-13 16:37:50 root] (omniquant.py 274): INFO layer 19 iter 3 loss:0.07384602725505829 norm:0.0007162050460465252 max memory_allocated 9923.2861328125 
[2026-01-13 16:37:55 root] (omniquant.py 274): INFO layer 19 iter 4 loss:0.0738079622387886 norm:0.0007131093880161643 max memory_allocated 9923.2861328125 
[2026-01-13 16:37:59 root] (omniquant.py 274): INFO layer 19 iter 5 loss:0.07376523315906525 norm:0.0007041027420200408 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:04 root] (omniquant.py 274): INFO layer 19 iter 6 loss:0.07371586561203003 norm:0.0006981489714235067 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:09 root] (omniquant.py 274): INFO layer 19 iter 7 loss:0.07361754775047302 norm:0.0006867421325296164 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:14 root] (omniquant.py 274): INFO layer 19 iter 8 loss:0.07355160266160965 norm:0.0006705144187435508 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:19 root] (omniquant.py 274): INFO layer 19 iter 9 loss:0.07351323962211609 norm:0.0006552308332175016 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:23 root] (omniquant.py 274): INFO layer 19 iter 10 loss:0.07348760962486267 norm:0.0006456678383983672 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:28 root] (omniquant.py 274): INFO layer 19 iter 11 loss:0.0734272301197052 norm:0.0006357789970934391 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:32 root] (omniquant.py 274): INFO layer 19 iter 12 loss:0.07334022223949432 norm:0.0006217659683898091 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:37 root] (omniquant.py 274): INFO layer 19 iter 13 loss:0.07333528250455856 norm:0.000611343770287931 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:41 root] (omniquant.py 274): INFO layer 19 iter 14 loss:0.0733291283249855 norm:0.0005687807570211589 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:46 root] (omniquant.py 274): INFO layer 19 iter 15 loss:0.07334226369857788 norm:0.0005590920918621123 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:51 root] (omniquant.py 274): INFO layer 19 iter 16 loss:0.07334680110216141 norm:0.0005583169986493886 max memory_allocated 9923.2861328125 
[2026-01-13 16:38:55 root] (omniquant.py 274): INFO layer 19 iter 17 loss:0.07335510849952698 norm:0.0005568255437538028 max memory_allocated 9923.2861328125 
[2026-01-13 16:39:00 root] (omniquant.py 274): INFO layer 19 iter 18 loss:0.07333729416131973 norm:0.0005578199052251875 max memory_allocated 9923.2861328125 
[2026-01-13 16:39:05 root] (omniquant.py 274): INFO layer 19 iter 19 loss:0.07334163039922714 norm:0.000557594234123826 max memory_allocated 9923.2861328125 
[2026-01-13 16:39:07 root] (omniquant.py 193): INFO === Start quantize layer 20 ===
[2026-01-13 16:39:13 root] (omniquant.py 274): INFO layer 20 iter 0 loss:0.08368327468633652 norm:0.0005331783904694021 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:18 root] (omniquant.py 274): INFO layer 20 iter 1 loss:0.08365102857351303 norm:0.0005322590004652739 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:22 root] (omniquant.py 274): INFO layer 20 iter 2 loss:0.08364415168762207 norm:0.0005325744859874249 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:27 root] (omniquant.py 274): INFO layer 20 iter 3 loss:0.08369258791208267 norm:0.0005401975940912962 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:32 root] (omniquant.py 274): INFO layer 20 iter 4 loss:0.08370929211378098 norm:0.0005395615007728338 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:36 root] (omniquant.py 274): INFO layer 20 iter 5 loss:0.08375606685876846 norm:0.0005416189087554812 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:41 root] (omniquant.py 274): INFO layer 20 iter 6 loss:0.08376435935497284 norm:0.0005404103430919349 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:46 root] (omniquant.py 274): INFO layer 20 iter 7 loss:0.08375857770442963 norm:0.0005409166915342212 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:50 root] (omniquant.py 274): INFO layer 20 iter 8 loss:0.0837486982345581 norm:0.000540384033229202 max memory_allocated 9923.9189453125 
[2026-01-13 16:39:55 root] (omniquant.py 274): INFO layer 20 iter 9 loss:0.08376281708478928 norm:0.0005469347233884037 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:00 root] (omniquant.py 274): INFO layer 20 iter 10 loss:0.08371293544769287 norm:0.0005442217225208879 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:04 root] (omniquant.py 274): INFO layer 20 iter 11 loss:0.08371168375015259 norm:0.0005455033970065415 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:09 root] (omniquant.py 274): INFO layer 20 iter 12 loss:0.08371862769126892 norm:0.0005431881872937083 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:13 root] (omniquant.py 274): INFO layer 20 iter 13 loss:0.08371428400278091 norm:0.00053938920609653 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:18 root] (omniquant.py 274): INFO layer 20 iter 14 loss:0.08372385799884796 norm:0.0005412638420239091 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:22 root] (omniquant.py 274): INFO layer 20 iter 15 loss:0.08371984958648682 norm:0.0005407261196523905 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:27 root] (omniquant.py 274): INFO layer 20 iter 16 loss:0.08369758725166321 norm:0.0005347649566829205 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:32 root] (omniquant.py 274): INFO layer 20 iter 17 loss:0.08371557295322418 norm:0.0005351240979507565 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:36 root] (omniquant.py 274): INFO layer 20 iter 18 loss:0.08369187265634537 norm:0.0005286810919642448 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:41 root] (omniquant.py 274): INFO layer 20 iter 19 loss:0.08369950205087662 norm:0.0005272255511954427 max memory_allocated 9923.9189453125 
[2026-01-13 16:40:42 root] (omniquant.py 193): INFO === Start quantize layer 21 ===
[2026-01-13 16:40:48 root] (omniquant.py 274): INFO layer 21 iter 0 loss:0.1019371822476387 norm:0.0006419841665774584 max memory_allocated 9924.5517578125 
[2026-01-13 16:40:52 root] (omniquant.py 274): INFO layer 21 iter 1 loss:0.10198138654232025 norm:0.0006422547157853842 max memory_allocated 9924.5517578125 
[2026-01-13 16:40:56 root] (omniquant.py 274): INFO layer 21 iter 2 loss:0.10199794918298721 norm:0.0006407474866136909 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:01 root] (omniquant.py 274): INFO layer 21 iter 3 loss:0.10194744169712067 norm:0.0006382812862284482 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:05 root] (omniquant.py 274): INFO layer 21 iter 4 loss:0.10189555585384369 norm:0.0006352051859721541 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:10 root] (omniquant.py 274): INFO layer 21 iter 5 loss:0.10182111710309982 norm:0.0006291157915256917 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:15 root] (omniquant.py 274): INFO layer 21 iter 6 loss:0.10184817016124725 norm:0.0006262271781452 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:19 root] (omniquant.py 274): INFO layer 21 iter 7 loss:0.10186073929071426 norm:0.0006270838784985244 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:24 root] (omniquant.py 274): INFO layer 21 iter 8 loss:0.10190512239933014 norm:0.0006259596557356417 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:28 root] (omniquant.py 274): INFO layer 21 iter 9 loss:0.10184486955404282 norm:0.0006239503854885697 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:33 root] (omniquant.py 274): INFO layer 21 iter 10 loss:0.10182444751262665 norm:0.0006196127505972981 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:37 root] (omniquant.py 274): INFO layer 21 iter 11 loss:0.1018093004822731 norm:0.0006243481184355915 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:42 root] (omniquant.py 274): INFO layer 21 iter 12 loss:0.10173878818750381 norm:0.0006186530808918178 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:47 root] (omniquant.py 274): INFO layer 21 iter 13 loss:0.10162269324064255 norm:0.0006109263049438596 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:52 root] (omniquant.py 274): INFO layer 21 iter 14 loss:0.10154138505458832 norm:0.0006041922606527805 max memory_allocated 9924.5517578125 
[2026-01-13 16:41:56 root] (omniquant.py 274): INFO layer 21 iter 15 loss:0.10167668759822845 norm:0.0006119563477113843 max memory_allocated 9924.5517578125 
[2026-01-13 16:42:01 root] (omniquant.py 274): INFO layer 21 iter 16 loss:0.10168296098709106 norm:0.0006134272553026676 max memory_allocated 9924.5517578125 
[2026-01-13 16:42:05 root] (omniquant.py 274): INFO layer 21 iter 17 loss:0.10167299956083298 norm:0.0006115640280768275 max memory_allocated 9924.5517578125 
[2026-01-13 16:42:10 root] (omniquant.py 274): INFO layer 21 iter 18 loss:0.10172818601131439 norm:0.0006100288010202348 max memory_allocated 9924.5517578125 
[2026-01-13 16:42:15 root] (omniquant.py 274): INFO layer 21 iter 19 loss:0.10186713933944702 norm:0.0006089313537813723 max memory_allocated 9924.5517578125 
[2026-01-13 16:42:17 root] (omniquant.py 193): INFO === Start quantize layer 22 ===
[2026-01-13 16:42:22 root] (omniquant.py 274): INFO layer 22 iter 0 loss:0.1196114718914032 norm:0.0005414902116172016 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:27 root] (omniquant.py 274): INFO layer 22 iter 1 loss:0.11959895491600037 norm:0.0005371338920667768 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:32 root] (omniquant.py 274): INFO layer 22 iter 2 loss:0.11955930292606354 norm:0.0005355214234441519 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:36 root] (omniquant.py 274): INFO layer 22 iter 3 loss:0.11952264606952667 norm:0.0005301361670717597 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:41 root] (omniquant.py 274): INFO layer 22 iter 4 loss:0.1194721981883049 norm:0.0005250765825621784 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:45 root] (omniquant.py 274): INFO layer 22 iter 5 loss:0.11940920352935791 norm:0.0005180040607228875 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:50 root] (omniquant.py 274): INFO layer 22 iter 6 loss:0.11937487125396729 norm:0.0005144794122315943 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:54 root] (omniquant.py 274): INFO layer 22 iter 7 loss:0.11938517540693283 norm:0.0005135526298545301 max memory_allocated 9925.1845703125 
[2026-01-13 16:42:59 root] (omniquant.py 274): INFO layer 22 iter 8 loss:0.1193191334605217 norm:0.0005096787353977561 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:03 root] (omniquant.py 274): INFO layer 22 iter 9 loss:0.1193481907248497 norm:0.0005096150562167168 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:08 root] (omniquant.py 274): INFO layer 22 iter 10 loss:0.119324691593647 norm:0.0005089300102554262 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:13 root] (omniquant.py 274): INFO layer 22 iter 11 loss:0.1191902756690979 norm:0.000495176063850522 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:17 root] (omniquant.py 274): INFO layer 22 iter 12 loss:0.11922457814216614 norm:0.0004966896958649158 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:22 root] (omniquant.py 274): INFO layer 22 iter 13 loss:0.11920196563005447 norm:0.000492519058752805 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:26 root] (omniquant.py 274): INFO layer 22 iter 14 loss:0.11922384053468704 norm:0.0004932760493829846 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:31 root] (omniquant.py 274): INFO layer 22 iter 15 loss:0.1192372515797615 norm:0.0004944900865666568 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:36 root] (omniquant.py 274): INFO layer 22 iter 16 loss:0.11922362446784973 norm:0.000493887928314507 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:41 root] (omniquant.py 274): INFO layer 22 iter 17 loss:0.1192241907119751 norm:0.0004939892678521574 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:45 root] (omniquant.py 274): INFO layer 22 iter 18 loss:0.11926117539405823 norm:0.0004966406850144267 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:50 root] (omniquant.py 274): INFO layer 22 iter 19 loss:0.1192515641450882 norm:0.0004955571494065225 max memory_allocated 9925.1845703125 
[2026-01-13 16:43:52 root] (omniquant.py 193): INFO === Start quantize layer 23 ===
[2026-01-13 16:43:58 root] (omniquant.py 274): INFO layer 23 iter 0 loss:0.14112889766693115 norm:0.0006891246302984655 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:02 root] (omniquant.py 274): INFO layer 23 iter 1 loss:0.1411484032869339 norm:0.0006843063165433705 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:07 root] (omniquant.py 274): INFO layer 23 iter 2 loss:0.14112070202827454 norm:0.000682719168253243 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:12 root] (omniquant.py 274): INFO layer 23 iter 3 loss:0.14106622338294983 norm:0.0006731341127306223 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:16 root] (omniquant.py 274): INFO layer 23 iter 4 loss:0.14105769991874695 norm:0.0006710183224640787 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:21 root] (omniquant.py 274): INFO layer 23 iter 5 loss:0.14103394746780396 norm:0.0006652341689914465 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:25 root] (omniquant.py 274): INFO layer 23 iter 6 loss:0.14099958539009094 norm:0.0006626925314776599 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:30 root] (omniquant.py 274): INFO layer 23 iter 7 loss:0.14098303020000458 norm:0.000655782176181674 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:35 root] (omniquant.py 274): INFO layer 23 iter 8 loss:0.14092659950256348 norm:0.0006453620735555887 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:40 root] (omniquant.py 274): INFO layer 23 iter 9 loss:0.1408957540988922 norm:0.000641405291389674 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:44 root] (omniquant.py 274): INFO layer 23 iter 10 loss:0.1408880054950714 norm:0.0006393106887117028 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:49 root] (omniquant.py 274): INFO layer 23 iter 11 loss:0.14089591801166534 norm:0.00063958769896999 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:54 root] (omniquant.py 274): INFO layer 23 iter 12 loss:0.14089630544185638 norm:0.0006361397099681199 max memory_allocated 9925.8173828125 
[2026-01-13 16:44:58 root] (omniquant.py 274): INFO layer 23 iter 13 loss:0.14090634882450104 norm:0.000638068187981844 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:03 root] (omniquant.py 274): INFO layer 23 iter 14 loss:0.14090770483016968 norm:0.0006376584060490131 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:08 root] (omniquant.py 274): INFO layer 23 iter 15 loss:0.1409403383731842 norm:0.0006417263648472726 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:12 root] (omniquant.py 274): INFO layer 23 iter 16 loss:0.14091350138187408 norm:0.0006429743370972574 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:17 root] (omniquant.py 274): INFO layer 23 iter 17 loss:0.1409095972776413 norm:0.0006400131969712675 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:21 root] (omniquant.py 274): INFO layer 23 iter 18 loss:0.1409103125333786 norm:0.0006408946355804801 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:26 root] (omniquant.py 274): INFO layer 23 iter 19 loss:0.14088588953018188 norm:0.0006376118399202824 max memory_allocated 9925.8173828125 
[2026-01-13 16:45:28 root] (omniquant.py 193): INFO === Start quantize layer 24 ===
[2026-01-13 16:45:34 root] (omniquant.py 274): INFO layer 24 iter 0 loss:0.16362150013446808 norm:0.000556106329895556 max memory_allocated 9926.4501953125 
[2026-01-13 16:45:39 root] (omniquant.py 274): INFO layer 24 iter 1 loss:0.16359052062034607 norm:0.0005513372016139328 max memory_allocated 9926.4501953125 
[2026-01-13 16:45:44 root] (omniquant.py 274): INFO layer 24 iter 2 loss:0.16355478763580322 norm:0.00054422568064183 max memory_allocated 9926.4501953125 
[2026-01-13 16:45:49 root] (omniquant.py 274): INFO layer 24 iter 3 loss:0.1635751873254776 norm:0.0005473847268149257 max memory_allocated 9926.4501953125 
[2026-01-13 16:45:53 root] (omniquant.py 274): INFO layer 24 iter 4 loss:0.1635618507862091 norm:0.0005460757529363036 max memory_allocated 9926.4501953125 
[2026-01-13 16:45:58 root] (omniquant.py 274): INFO layer 24 iter 5 loss:0.16355016827583313 norm:0.0005440819659270346 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:02 root] (omniquant.py 274): INFO layer 24 iter 6 loss:0.16348159313201904 norm:0.000536623818334192 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:07 root] (omniquant.py 274): INFO layer 24 iter 7 loss:0.16343671083450317 norm:0.000528736156411469 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:11 root] (omniquant.py 274): INFO layer 24 iter 8 loss:0.16343408823013306 norm:0.0005284609505906701 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:16 root] (omniquant.py 274): INFO layer 24 iter 9 loss:0.16342128813266754 norm:0.0005239496240392327 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:21 root] (omniquant.py 274): INFO layer 24 iter 10 loss:0.1634346842765808 norm:0.0005234383279457688 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:25 root] (omniquant.py 274): INFO layer 24 iter 11 loss:0.16342586278915405 norm:0.0005225030472502112 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:30 root] (omniquant.py 274): INFO layer 24 iter 12 loss:0.16340500116348267 norm:0.0005166803603060544 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:34 root] (omniquant.py 274): INFO layer 24 iter 13 loss:0.1634158045053482 norm:0.0005168111529201269 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:39 root] (omniquant.py 274): INFO layer 24 iter 14 loss:0.16342200338840485 norm:0.0005177090642973781 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:43 root] (omniquant.py 274): INFO layer 24 iter 15 loss:0.16341960430145264 norm:0.0005166309420019388 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:48 root] (omniquant.py 274): INFO layer 24 iter 16 loss:0.16343587636947632 norm:0.0005128083284944296 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:53 root] (omniquant.py 274): INFO layer 24 iter 17 loss:0.16341577470302582 norm:0.0005080454284325242 max memory_allocated 9926.4501953125 
[2026-01-13 16:46:58 root] (omniquant.py 274): INFO layer 24 iter 18 loss:0.16344210505485535 norm:0.0005084950826130807 max memory_allocated 9926.4501953125 
[2026-01-13 16:47:02 root] (omniquant.py 274): INFO layer 24 iter 19 loss:0.1633935123682022 norm:0.0005014389171265066 max memory_allocated 9926.4501953125 
[2026-01-13 16:47:03 root] (omniquant.py 193): INFO === Start quantize layer 25 ===
[2026-01-13 16:47:09 root] (omniquant.py 274): INFO layer 25 iter 0 loss:0.19334925711154938 norm:0.000921691651456058 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:14 root] (omniquant.py 274): INFO layer 25 iter 1 loss:0.1933319866657257 norm:0.0009158430621027946 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:18 root] (omniquant.py 274): INFO layer 25 iter 2 loss:0.19334641098976135 norm:0.0009132759878411889 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:23 root] (omniquant.py 274): INFO layer 25 iter 3 loss:0.1933036595582962 norm:0.0009142054477706552 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:27 root] (omniquant.py 274): INFO layer 25 iter 4 loss:0.19325007498264313 norm:0.0009057118440978229 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:32 root] (omniquant.py 274): INFO layer 25 iter 5 loss:0.19315384328365326 norm:0.0008990906062535942 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:37 root] (omniquant.py 274): INFO layer 25 iter 6 loss:0.19306936860084534 norm:0.0008957595564424992 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:41 root] (omniquant.py 274): INFO layer 25 iter 7 loss:0.19300898909568787 norm:0.0008917812956497073 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:46 root] (omniquant.py 274): INFO layer 25 iter 8 loss:0.19283802807331085 norm:0.0008782852673903108 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:51 root] (omniquant.py 274): INFO layer 25 iter 9 loss:0.19270795583724976 norm:0.0008693663985468447 max memory_allocated 9927.0830078125 
[2026-01-13 16:47:56 root] (omniquant.py 274): INFO layer 25 iter 10 loss:0.19266226887702942 norm:0.0008685412467457354 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:00 root] (omniquant.py 274): INFO layer 25 iter 11 loss:0.19268135726451874 norm:0.0008682672632858157 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:05 root] (omniquant.py 274): INFO layer 25 iter 12 loss:0.19266462326049805 norm:0.0008653598488308489 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:10 root] (omniquant.py 274): INFO layer 25 iter 13 loss:0.19270271062850952 norm:0.0008673990378156304 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:15 root] (omniquant.py 274): INFO layer 25 iter 14 loss:0.1926978975534439 norm:0.0008691747207194567 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:20 root] (omniquant.py 274): INFO layer 25 iter 15 loss:0.1927056461572647 norm:0.0008754573063924909 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:25 root] (omniquant.py 274): INFO layer 25 iter 16 loss:0.19264565408229828 norm:0.0008726728847250342 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:29 root] (omniquant.py 274): INFO layer 25 iter 17 loss:0.1927356868982315 norm:0.0008707878878340125 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:34 root] (omniquant.py 274): INFO layer 25 iter 18 loss:0.19260162115097046 norm:0.0008614215767011046 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:39 root] (omniquant.py 274): INFO layer 25 iter 19 loss:0.19260774552822113 norm:0.000868126458954066 max memory_allocated 9927.0830078125 
[2026-01-13 16:48:41 root] (omniquant.py 193): INFO === Start quantize layer 26 ===
[2026-01-13 16:48:47 root] (omniquant.py 274): INFO layer 26 iter 0 loss:0.2292475700378418 norm:0.0009311148896813393 max memory_allocated 9927.7158203125 
[2026-01-13 16:48:52 root] (omniquant.py 274): INFO layer 26 iter 1 loss:0.2293565571308136 norm:0.0009336652001366019 max memory_allocated 9927.7158203125 
[2026-01-13 16:48:57 root] (omniquant.py 274): INFO layer 26 iter 2 loss:0.22941306233406067 norm:0.0009301214595325291 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:02 root] (omniquant.py 274): INFO layer 26 iter 3 loss:0.2293790876865387 norm:0.0009251742158085108 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:07 root] (omniquant.py 274): INFO layer 26 iter 4 loss:0.22941820323467255 norm:0.0009212309378199279 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:11 root] (omniquant.py 274): INFO layer 26 iter 5 loss:0.2294079065322876 norm:0.0009207803523167968 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:16 root] (omniquant.py 274): INFO layer 26 iter 6 loss:0.22943250834941864 norm:0.0009169702534563839 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:21 root] (omniquant.py 274): INFO layer 26 iter 7 loss:0.22948379814624786 norm:0.0009178403415717185 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:25 root] (omniquant.py 274): INFO layer 26 iter 8 loss:0.2295515239238739 norm:0.0009169395780190825 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:30 root] (omniquant.py 274): INFO layer 26 iter 9 loss:0.22959209978580475 norm:0.0009168878896161914 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:34 root] (omniquant.py 274): INFO layer 26 iter 10 loss:0.22955109179019928 norm:0.0009076514979824424 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:39 root] (omniquant.py 274): INFO layer 26 iter 11 loss:0.22952407598495483 norm:0.0009052606183104217 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:44 root] (omniquant.py 274): INFO layer 26 iter 12 loss:0.22956840693950653 norm:0.0009044953621923923 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:48 root] (omniquant.py 274): INFO layer 26 iter 13 loss:0.22954106330871582 norm:0.0008980215061455965 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:53 root] (omniquant.py 274): INFO layer 26 iter 14 loss:0.2295333445072174 norm:0.0008933698991313577 max memory_allocated 9927.7158203125 
[2026-01-13 16:49:57 root] (omniquant.py 274): INFO layer 26 iter 15 loss:0.22955739498138428 norm:0.0008923260611481965 max memory_allocated 9927.7158203125 
[2026-01-13 16:50:02 root] (omniquant.py 274): INFO layer 26 iter 16 loss:0.2296234518289566 norm:0.0008954895311035216 max memory_allocated 9927.7158203125 
[2026-01-13 16:50:07 root] (omniquant.py 274): INFO layer 26 iter 17 loss:0.22960028052330017 norm:0.0008925676811486483 max memory_allocated 9927.7158203125 
[2026-01-13 16:50:11 root] (omniquant.py 274): INFO layer 26 iter 18 loss:0.22955918312072754 norm:0.0008911164477467537 max memory_allocated 9927.7158203125 
[2026-01-13 16:50:16 root] (omniquant.py 274): INFO layer 26 iter 19 loss:0.22952872514724731 norm:0.0008937179227359593 max memory_allocated 9927.7158203125 
[2026-01-13 16:50:18 root] (omniquant.py 193): INFO === Start quantize layer 27 ===
[2026-01-13 16:50:24 root] (omniquant.py 274): INFO layer 27 iter 0 loss:0.27413100004196167 norm:0.0015809315955266356 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:28 root] (omniquant.py 274): INFO layer 27 iter 1 loss:0.2740575969219208 norm:0.0015775925712659955 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:33 root] (omniquant.py 274): INFO layer 27 iter 2 loss:0.2740352153778076 norm:0.0015783634735271335 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:38 root] (omniquant.py 274): INFO layer 27 iter 3 loss:0.27395322918891907 norm:0.0015637369360774755 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:43 root] (omniquant.py 274): INFO layer 27 iter 4 loss:0.27404847741127014 norm:0.0015729106962680817 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:48 root] (omniquant.py 274): INFO layer 27 iter 5 loss:0.2740277349948883 norm:0.0015745279379189014 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:52 root] (omniquant.py 274): INFO layer 27 iter 6 loss:0.27405083179473877 norm:0.0015866270987316966 max memory_allocated 9928.3486328125 
[2026-01-13 16:50:57 root] (omniquant.py 274): INFO layer 27 iter 7 loss:0.2741580307483673 norm:0.0015909683424979448 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:02 root] (omniquant.py 274): INFO layer 27 iter 8 loss:0.27424150705337524 norm:0.0015966023784130812 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:07 root] (omniquant.py 274): INFO layer 27 iter 9 loss:0.2743701636791229 norm:0.0016060194466263056 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:12 root] (omniquant.py 274): INFO layer 27 iter 10 loss:0.27444058656692505 norm:0.001629436737857759 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:17 root] (omniquant.py 274): INFO layer 27 iter 11 loss:0.27442872524261475 norm:0.0016445344081148505 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:21 root] (omniquant.py 274): INFO layer 27 iter 12 loss:0.27455148100852966 norm:0.0016515220049768686 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:26 root] (omniquant.py 274): INFO layer 27 iter 13 loss:0.2745516002178192 norm:0.0016407830407842994 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:30 root] (omniquant.py 274): INFO layer 27 iter 14 loss:0.27441778779029846 norm:0.0016135446494445205 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:35 root] (omniquant.py 274): INFO layer 27 iter 15 loss:0.2742675840854645 norm:0.0016058043111115694 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:40 root] (omniquant.py 274): INFO layer 27 iter 16 loss:0.2742277979850769 norm:0.00160062569193542 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:44 root] (omniquant.py 274): INFO layer 27 iter 17 loss:0.2740788757801056 norm:0.001580704003572464 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:49 root] (omniquant.py 274): INFO layer 27 iter 18 loss:0.274080753326416 norm:0.0015764653217047453 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:54 root] (omniquant.py 274): INFO layer 27 iter 19 loss:0.2741025388240814 norm:0.001565289101563394 max memory_allocated 9928.3486328125 
[2026-01-13 16:51:55 root] (omniquant.py 193): INFO === Start quantize layer 28 ===
[2026-01-13 16:52:01 root] (omniquant.py 274): INFO layer 28 iter 0 loss:0.33141958713531494 norm:0.0019960179924964905 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:05 root] (omniquant.py 274): INFO layer 28 iter 1 loss:0.3311524987220764 norm:0.0019751021172851324 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:10 root] (omniquant.py 274): INFO layer 28 iter 2 loss:0.33107081055641174 norm:0.001969055738300085 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:14 root] (omniquant.py 274): INFO layer 28 iter 3 loss:0.3311322033405304 norm:0.0019628433510661125 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:19 root] (omniquant.py 274): INFO layer 28 iter 4 loss:0.33114975690841675 norm:0.0019586931448429823 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:23 root] (omniquant.py 274): INFO layer 28 iter 5 loss:0.3312664031982422 norm:0.001973301637917757 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:28 root] (omniquant.py 274): INFO layer 28 iter 6 loss:0.33122360706329346 norm:0.0019588028080761433 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:32 root] (omniquant.py 274): INFO layer 28 iter 7 loss:0.3303619623184204 norm:0.0018827886087819934 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:37 root] (omniquant.py 274): INFO layer 28 iter 8 loss:0.3304808735847473 norm:0.0018809876637533307 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:42 root] (omniquant.py 274): INFO layer 28 iter 9 loss:0.3307911157608032 norm:0.0018893217202275991 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:46 root] (omniquant.py 274): INFO layer 28 iter 10 loss:0.3309955596923828 norm:0.0018715221667662263 max memory_allocated 9928.9814453125 
[2026-01-13 16:52:54 root] (omniquant.py 274): INFO layer 28 iter 11 loss:0.330841988325119 norm:0.001835938193835318 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:02 root] (omniquant.py 274): INFO layer 28 iter 12 loss:0.3306456208229065 norm:0.0018004963640123606 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:11 root] (omniquant.py 274): INFO layer 28 iter 13 loss:0.3302549123764038 norm:0.0017549218609929085 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:20 root] (omniquant.py 274): INFO layer 28 iter 14 loss:0.3301995098590851 norm:0.001747459638863802 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:26 root] (omniquant.py 274): INFO layer 28 iter 15 loss:0.33010274171829224 norm:0.001733320765197277 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:35 root] (omniquant.py 274): INFO layer 28 iter 16 loss:0.32993125915527344 norm:0.0017190248472616076 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:43 root] (omniquant.py 274): INFO layer 28 iter 17 loss:0.3299534022808075 norm:0.0017186454497277737 max memory_allocated 9928.9814453125 
[2026-01-13 16:53:52 root] (omniquant.py 274): INFO layer 28 iter 18 loss:0.32997915148735046 norm:0.00172068877145648 max memory_allocated 9928.9814453125 
[2026-01-13 16:54:01 root] (omniquant.py 274): INFO layer 28 iter 19 loss:0.3299051523208618 norm:0.0017126082675531507 max memory_allocated 9928.9814453125 
[2026-01-13 16:54:04 root] (omniquant.py 193): INFO === Start quantize layer 29 ===
[2026-01-13 16:54:24 root] (omniquant.py 274): INFO layer 29 iter 0 loss:0.4129960834980011 norm:0.0034048331435769796 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:28 root] (omniquant.py 274): INFO layer 29 iter 1 loss:0.41292619705200195 norm:0.003393264953047037 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:33 root] (omniquant.py 274): INFO layer 29 iter 2 loss:0.4128418564796448 norm:0.0033689134288579226 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:37 root] (omniquant.py 274): INFO layer 29 iter 3 loss:0.4124613404273987 norm:0.0033459081314504147 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:42 root] (omniquant.py 274): INFO layer 29 iter 4 loss:0.4123419225215912 norm:0.0033501721918582916 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:46 root] (omniquant.py 274): INFO layer 29 iter 5 loss:0.4123857617378235 norm:0.003340313443914056 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:51 root] (omniquant.py 274): INFO layer 29 iter 6 loss:0.4123908281326294 norm:0.0033222376368939877 max memory_allocated 9929.6142578125 
[2026-01-13 16:54:55 root] (omniquant.py 274): INFO layer 29 iter 7 loss:0.4124242067337036 norm:0.003321585012599826 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:00 root] (omniquant.py 274): INFO layer 29 iter 8 loss:0.412479430437088 norm:0.0033318600617349148 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:04 root] (omniquant.py 274): INFO layer 29 iter 9 loss:0.41265514492988586 norm:0.00336213200353086 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:09 root] (omniquant.py 274): INFO layer 29 iter 10 loss:0.41263505816459656 norm:0.003367297351360321 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:13 root] (omniquant.py 274): INFO layer 29 iter 11 loss:0.41262152791023254 norm:0.0033608670346438885 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:18 root] (omniquant.py 274): INFO layer 29 iter 12 loss:0.4124099910259247 norm:0.003334461245685816 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:23 root] (omniquant.py 274): INFO layer 29 iter 13 loss:0.4125214219093323 norm:0.003344896249473095 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:28 root] (omniquant.py 274): INFO layer 29 iter 14 loss:0.4126524329185486 norm:0.00337035208940506 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:32 root] (omniquant.py 274): INFO layer 29 iter 15 loss:0.4123094379901886 norm:0.003342997282743454 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:37 root] (omniquant.py 274): INFO layer 29 iter 16 loss:0.41219785809516907 norm:0.0033311662264168262 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:42 root] (omniquant.py 274): INFO layer 29 iter 17 loss:0.4121829867362976 norm:0.003327031619846821 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:46 root] (omniquant.py 274): INFO layer 29 iter 18 loss:0.412401407957077 norm:nan max memory_allocated 9929.6142578125 
[2026-01-13 16:55:51 root] (omniquant.py 274): INFO layer 29 iter 19 loss:0.41228076815605164 norm:0.0033392542973160744 max memory_allocated 9929.6142578125 
[2026-01-13 16:55:53 root] (omniquant.py 193): INFO === Start quantize layer 30 ===
[2026-01-13 16:55:59 root] (omniquant.py 274): INFO layer 30 iter 0 loss:0.5495397448539734 norm:nan max memory_allocated 9930.2470703125 
[2026-01-13 16:56:03 root] (omniquant.py 274): INFO layer 30 iter 1 loss:0.5499359965324402 norm:0.004572904668748379 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:08 root] (omniquant.py 274): INFO layer 30 iter 2 loss:0.5499203205108643 norm:0.004571899771690369 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:13 root] (omniquant.py 274): INFO layer 30 iter 3 loss:0.5499985814094543 norm:0.004554912447929382 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:17 root] (omniquant.py 274): INFO layer 30 iter 4 loss:0.5501899719238281 norm:0.004551933612674475 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:22 root] (omniquant.py 274): INFO layer 30 iter 5 loss:0.5504841804504395 norm:0.004542149603366852 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:26 root] (omniquant.py 274): INFO layer 30 iter 6 loss:0.5508816242218018 norm:0.004543083254247904 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:31 root] (omniquant.py 274): INFO layer 30 iter 7 loss:0.5510644316673279 norm:0.004531713202595711 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:35 root] (omniquant.py 274): INFO layer 30 iter 8 loss:0.5510802268981934 norm:0.004536595195531845 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:40 root] (omniquant.py 274): INFO layer 30 iter 9 loss:0.5510267019271851 norm:0.004527066834270954 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:45 root] (omniquant.py 274): INFO layer 30 iter 10 loss:0.5508886575698853 norm:0.004518465604633093 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:49 root] (omniquant.py 274): INFO layer 30 iter 11 loss:0.5503790974617004 norm:0.004517459310591221 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:54 root] (omniquant.py 274): INFO layer 30 iter 12 loss:0.550423800945282 norm:0.004509984981268644 max memory_allocated 9930.2470703125 
[2026-01-13 16:56:58 root] (omniquant.py 274): INFO layer 30 iter 13 loss:0.5505108833312988 norm:0.004482844844460487 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:02 root] (omniquant.py 274): INFO layer 30 iter 14 loss:0.5504912734031677 norm:0.004473567008972168 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:07 root] (omniquant.py 274): INFO layer 30 iter 15 loss:0.5506564378738403 norm:0.004456076305359602 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:11 root] (omniquant.py 274): INFO layer 30 iter 16 loss:0.5507388114929199 norm:0.004452096298336983 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:16 root] (omniquant.py 274): INFO layer 30 iter 17 loss:0.5508189797401428 norm:0.004436097107827663 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:20 root] (omniquant.py 274): INFO layer 30 iter 18 loss:0.550645112991333 norm:0.004426375962793827 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:25 root] (omniquant.py 274): INFO layer 30 iter 19 loss:0.5500340461730957 norm:0.0044306423515081406 max memory_allocated 9930.2470703125 
[2026-01-13 16:57:27 root] (omniquant.py 193): INFO === Start quantize layer 31 ===
[2026-01-13 16:57:33 root] (omniquant.py 274): INFO layer 31 iter 0 loss:1.1470973491668701 norm:nan max memory_allocated 9930.8798828125 
[2026-01-13 16:57:38 root] (omniquant.py 274): INFO layer 31 iter 1 loss:1.1461071968078613 norm:0.01007885206490755 max memory_allocated 9930.8798828125 
[2026-01-13 16:57:42 root] (omniquant.py 274): INFO layer 31 iter 2 loss:1.1451666355133057 norm:0.010043539106845856 max memory_allocated 9930.8798828125 
[2026-01-13 16:57:47 root] (omniquant.py 274): INFO layer 31 iter 3 loss:1.1440942287445068 norm:0.009968488477170467 max memory_allocated 9930.8798828125 
[2026-01-13 16:57:51 root] (omniquant.py 274): INFO layer 31 iter 4 loss:1.1444393396377563 norm:0.009972445666790009 max memory_allocated 9930.8798828125 
[2026-01-13 16:57:56 root] (omniquant.py 274): INFO layer 31 iter 5 loss:1.1443909406661987 norm:0.009983633644878864 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:00 root] (omniquant.py 274): INFO layer 31 iter 6 loss:1.1444052457809448 norm:0.010025013238191605 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:05 root] (omniquant.py 274): INFO layer 31 iter 7 loss:1.1447386741638184 norm:0.010002529248595238 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:09 root] (omniquant.py 274): INFO layer 31 iter 8 loss:1.1452200412750244 norm:0.010072239674627781 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:14 root] (omniquant.py 274): INFO layer 31 iter 9 loss:1.1453171968460083 norm:0.010014149360358715 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:19 root] (omniquant.py 274): INFO layer 31 iter 10 loss:1.144955039024353 norm:0.009916971437633038 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:23 root] (omniquant.py 274): INFO layer 31 iter 11 loss:1.1448159217834473 norm:0.00996898952871561 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:28 root] (omniquant.py 274): INFO layer 31 iter 12 loss:1.1444828510284424 norm:0.009937060065567493 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:33 root] (omniquant.py 274): INFO layer 31 iter 13 loss:1.1440508365631104 norm:0.009876705706119537 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:37 root] (omniquant.py 274): INFO layer 31 iter 14 loss:1.1437244415283203 norm:0.00986661110073328 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:42 root] (omniquant.py 274): INFO layer 31 iter 15 loss:1.1439975500106812 norm:nan max memory_allocated 9930.8798828125 
[2026-01-13 16:58:47 root] (omniquant.py 274): INFO layer 31 iter 16 loss:1.1440563201904297 norm:0.009787319228053093 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:51 root] (omniquant.py 274): INFO layer 31 iter 17 loss:1.1447869539260864 norm:0.009799502789974213 max memory_allocated 9930.8798828125 
[2026-01-13 16:58:56 root] (omniquant.py 274): INFO layer 31 iter 18 loss:1.1443792581558228 norm:0.009771551005542278 max memory_allocated 9930.8798828125 
[2026-01-13 16:59:01 root] (omniquant.py 274): INFO layer 31 iter 19 loss:1.1446893215179443 norm:0.009793376550078392 max memory_allocated 9930.8798828125 
[2026-01-13 16:59:04 root] (main.py 490): INFO quantization done in 3037.28s
[2026-01-13 16:59:04 root] (main.py 328): INFO === PPL evaluation (quantized_post_finetune) ===
